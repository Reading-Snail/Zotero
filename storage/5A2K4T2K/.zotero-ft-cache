
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2103.00020

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 26 Feb 2021]
Title: Learning Transferable Visual Models From Natural Language Supervision
Authors: Alec Radford , Jong Wook Kim , Chris Hallacy , Aditya Ramesh , Gabriel Goh , Sandhini Agarwal , Girish Sastry , Amanda Askell , Pamela Mishkin , Jack Clark , Gretchen Krueger , Ilya Sutskever
View a PDF of the paper titled Learning Transferable Visual Models From Natural Language Supervision, by Alec Radford and 11 other authors
View PDF

    Abstract: State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at this https URL . 

Subjects: 	Computer Vision and Pattern Recognition (cs.CV) ; Machine Learning (cs.LG)
Cite as: 	arXiv:2103.00020 [cs.CV]
  	(or arXiv:2103.00020v1 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2103.00020
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Jong Wook Kim [ view email ]
[v1] Fri, 26 Feb 2021 19:04:58 UTC (6,174 KB)
Full-text links:
Access Paper:

    View a PDF of the paper titled Learning Transferable Visual Models From Natural Language Supervision, by Alec Radford and 11 other authors
    View PDF
    TeX Source
    Other Formats 

view license
Current browse context:
cs.CV
< prev   |   next >
new | recent | 2021-03
Change to browse by:
cs
cs.LG
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

16 blog links
( what is this? )
DBLP - CS Bibliography
listing | bibtex
Alec Radford
Jong Wook Kim
Aditya Ramesh
Gabriel Goh
Girish Sastry
â€¦
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

