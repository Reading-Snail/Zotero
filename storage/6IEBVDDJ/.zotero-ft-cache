
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2210.03629

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 6 Oct 2022 ( v1 ), last revised 10 Mar 2023 (this version, v3)]
Title: ReAct: Synergizing Reasoning and Acting in Language Models
Authors: Shunyu Yao , Jeffrey Zhao , Dian Yu , Nan Du , Izhak Shafran , Karthik Narasimhan , Yuan Cao
View a PDF of the paper titled ReAct: Synergizing Reasoning and Acting in Language Models, by Shunyu Yao and 6 other authors
View PDF

    Abstract: While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Project site with code: this https URL 

Comments: 	v3 is the ICLR camera ready version with some typos fixed. Project site with code: this https URL
Subjects: 	Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
Cite as: 	arXiv:2210.03629 [cs.CL]
  	(or arXiv:2210.03629v3 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2210.03629
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Shunyu Yao [ view email ]
[v1] Thu, 6 Oct 2022 01:00:32 UTC (538 KB)
[v2] Sun, 27 Nov 2022 22:55:54 UTC (538 KB)
[v3] Fri, 10 Mar 2023 01:00:17 UTC (1,256 KB)
Full-text links:
Access Paper:

    View a PDF of the paper titled ReAct: Synergizing Reasoning and Acting in Language Models, by Shunyu Yao and 6 other authors
    View PDF
    TeX Source
    Other Formats 

license icon view license
Current browse context:
cs.CL
< prev   |   next >
new | recent | 2022-10
Change to browse by:
cs
cs.AI
cs.LG
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

10 blog links
( what is this? )
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

